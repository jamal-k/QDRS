# -*- coding: utf-8 -*-
"""CSC420Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-qlyf6CSqqnvpF-ZlHsgjHXILAEAZZsV
"""

!pip install quickdraw

"""# Data Processing and Visualization"""

import itertools
import matplotlib.pyplot as plt
from quickdraw import QuickDrawDataGroup
import numpy as np

categories = ['apple', 'basketball', 'cookie', 'dolphin', 'envelope', 'fish', 'golf club', 'headphones', 'ice cream', 'light bulb']
images = []
fig, ax = plt.subplots(2, 5, figsize=(20, 10))

for cat in categories:
  qd = QuickDrawDataGroup(cat, print_messages=False)
  for drawing in itertools.islice(qd.drawings, 1, 2):
    images.append(drawing.image)

ax[0, 0].imshow(images[0])
ax[0, 0].set_title(categories[0])
ax[0, 1].imshow(images[1])
ax[0, 1].set_title(categories[1])
ax[0, 2].imshow(images[2])
ax[0, 2].set_title(categories[2])
ax[0, 3].imshow(images[3])
ax[0, 3].set_title(categories[3])
ax[0, 4].imshow(images[4])
ax[0, 4].set_title(categories[4])
ax[1, 0].imshow(images[5])
ax[1, 0].set_title(categories[5])
ax[1, 1].imshow(images[6])
ax[1, 1].set_title(categories[6])
ax[1, 2].imshow(images[7])
ax[1, 2].set_title(categories[7])
ax[1, 3].imshow(images[8])
ax[1, 3].set_title(categories[8])
ax[1, 4].imshow(images[9])
ax[1, 4].set_title(categories[9])

import PIL
from PIL import Image, ImageDraw, ImageOps

qd2 = QuickDrawDataGroup('cookie', print_messages=False)
fig2, ax2 = plt.subplots(2, 4, figsize=(20, 10))
back = Image.new("RGB", (255, 255))
strokes = []

for drawing in itertools.islice(qd2.drawings, 1):
    print(drawing.no_of_strokes)
    for stroke in drawing.strokes:
      img = ImageDraw.Draw(back)
      img.line(stroke, width=2)
      temp = back.copy()
      strokes.append(temp)

ax2[0][0].imshow(strokes[1])
ax2[0][1].imshow(strokes[2])
ax2[0][2].imshow(strokes[3])
ax2[0][3].imshow(strokes[4])
ax2[1][0].imshow(strokes[5])
ax2[1][1].imshow(strokes[6])
ax2[1][2].imshow(strokes[7])
ax2[1][2].set_title('Reconstruction')
temp = ImageOps.invert(drawing.image)
ax2[1][3].imshow(temp)
ax2[1][3].set_title('Actual')

import torch
from torchvision import transforms

def get_image_data(group, label, start=0, stop=100):
  if group == None:
    return [], []
  qd = QuickDrawDataGroup(group, print_messages=False)
  data = []
  labels = []

  for drawing in itertools.islice(qd.drawings, start, stop):
    image = drawing.image#.convert('L')
    image = transforms.ToTensor()(image)
    data.append(image)
    labels.append(label)
  
  return data, labels

from torch.utils.data import Dataset
 
class DrawingDataset(Dataset):
  def __init__(self, cat1, cat2, cat3, cat4, cat5, cat6, cat7, cat8, cat9, cat10, start=0, stop=100):
    data1, labels1 = get_image_data(cat1, 0, start, stop)
    data2, labels2 = get_image_data(cat2, 1, start, stop)
    data3, labels3 = get_image_data(cat3, 2, start, stop)
    data4, labels4 = get_image_data(cat4, 3, start, stop)
    data5, labels5 = get_image_data(cat5, 4, start, stop)
    data6, labels6 = get_image_data(cat6, 5, start, stop)
    data7, labels7 = get_image_data(cat7, 6, start, stop)
    data8, labels8 = get_image_data(cat8, 7, start, stop)
    data9, labels9 = get_image_data(cat9, 8, start, stop)
    data10, labels10 = get_image_data(cat10, 9, start, stop)
    self.data = data1 + data2 + data3 + data4 + data5 + data6 + data7 + data8 + data9 + data10
    self.labels = labels1 + labels2 + labels3 + labels4 + labels5 + labels6 + labels7 + labels8 + labels9 + labels10
 
  def __len__(self):
      return len(self.data)
 
  def __getitem__(self, idx):
      return self.data[idx], self.labels[idx]

import numpy as np

train_dataset = DrawingDataset('apple', 'basketball', 'cookie', 'dolphin', 'envelope', 'fish', 'golf club', 'headphones', 'ice cream', 'light bulb')
val_dataset = DrawingDataset('apple', 'basketball', 'cookie', 'dolphin', 'envelope', 'fish', 'golf club', 'headphones', 'ice cream', 'light bulb', 100, 120)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=20)

"""# Transfer Learning CNN"""

import torchvision.models
!rm -rf /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth
!wget https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth -P /root/.cache/torch/checkpoints/
alexnet = torchvision.models.alexnet(pretrained=True)

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

class CNNModel(nn.Module):
  def __init__(self):
    super(CNNModel, self).__init__()
    self.fc1 = nn.Linear(256*7*7, 32)
    self.fc2 = nn.Linear(32, 10)
  
  def forward(self, x):
    x = x.view(-1, 256*7*7)
    x = F.relu(self.fc1(x))
    x = self.fc2(x)
    return x

def get_accuracy(model, dataloader, CNN=True, class_acc=False):
    correct, total = 0, 0
    for imgs, labels in dataloader:
      if CNN:
        imgs = alexnet.features(imgs)
      else:
        imgs = imgs.squeeze()

      #To Enable GPU Usage
      if use_cuda and torch.cuda.is_available():
        imgs = imgs.cuda()
        labels = labels.cuda()
      
      output = model(imgs)
      #select index with maximum prediction score
      pred = output.max(1, keepdim=True)[1]
      correct += pred.eq(labels.view_as(pred)).sum().item()
      total += imgs.shape[0]

      if class_acc:
        classes = ['Apple', 'Basketball', 'Cookie', 'Dolphin', 'Envelope', 'Fish', 'Golf Club', 'Headphones', 'Ice Cream', 'Light Bulb']
        print('{} Classification Accuracy: {:.3f}'.format(classes[labels[0]], correct/total))
    
    if class_acc:
      return

    return correct / total

import copy

def train_CNN(model, train_loader, val_loader, batch_size=64, num_epochs=5, CNN=True):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)
    epochs, losses, train_acc, val_acc = [], [], [], []
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    # training
    n = 0 # the number of epochs
    for epoch in range(num_epochs):
        epochs.append(n)
        n += 1
        for imgs, labels in train_loader:
            if CNN:
              imgs = alexnet.features(imgs)
            else:
              imgs = imgs.squeeze()

            #To Enable GPU Usage
            if use_cuda and torch.cuda.is_available():
              imgs = imgs.cuda()
              labels = labels.cuda()
             
            out = model(imgs)
            #print(out)
            #print(labels)
            loss = criterion(out, labels) # compute the total loss
            loss.backward()               # backward pass (compute parameter updates)
            optimizer.step()              # make the updates for each parameter
            optimizer.zero_grad()         # a clean up step for PyTorch

        # save the current training information
        losses.append(float(loss)/batch_size)             # compute *average* loss
        if CNN:
          train_acc.append(get_accuracy(model, train_loader)) # compute training accuracy 
          val_acc.append(get_accuracy(model, val_loader))  # compute validation accuracy
          print("Epoch {} Training Accuracy: {}".format(n, train_acc[-1]))
          print("Epoch {} Validation Accuracy: {}".format(n, val_acc[-1]))
        else:
          train_acc.append(get_accuracy(model, train_loader, CNN=False)) # compute training accuracy 
          val_acc.append(get_accuracy(model, val_loader, CNN=False))  # compute validation accuracy
          print("Epoch {} Training Accuracy: {}".format(n, train_acc[-1]))
          print("Epoch {} Validation Accuracy: {}".format(n, val_acc[-1]))
        # deep copy the model
        if val_acc[-1] > best_acc:
          best_acc = val_acc[-1]
          best_model_wts = copy.deepcopy(model.state_dict())
      
    #plotting
    plt.title("Training Curve")
    plt.plot(epochs, losses, label="Train")
    plt.xlabel("Iterations")
    plt.ylabel("Loss")
    plt.show()

    plt.title("Training Curve")
    plt.plot(epochs, train_acc, label="Train")
    plt.plot(epochs, val_acc, label="Validation")
    plt.xlabel("Epochs")
    plt.ylabel("Training Accuracy")
    plt.legend(loc='best')
    plt.show()

    # load best model weights
    model.load_state_dict(best_model_wts)
    print("Final Training Accuracy: {}".format(train_acc[-1]))
    print("Final Validation Accuracy: {}".format(val_acc[-1]))
    return model

model = CNNModel()

use_cuda = True
if use_cuda and torch.cuda.is_available():
  model.cuda()
  print('CUDA is available!  Training on GPU ...')

trained_model = train_CNN(model, train_loader, val_loader, num_epochs=5)

get_accuracy(trained_model, val_loader, class_acc=True)

for i, (inputs, labels) in enumerate(val_loader):
    classes = ['Apple', 'Basketball', 'Cookie', 'Dolphin', 'Envelope', 'Fish', 'Golf Club', 'Headphones', 'Ice Cream', 'Light Bulb']  
    features = alexnet.features(inputs)
    outputs = trained_model(features)
    _, preds = torch.max(outputs, 1)

    fig = plt.figure(figsize=(20, 10))
    for idx in range(5):
        ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])
        plt.imshow(transforms.ToPILImage()(inputs[idx]))
        ax.set_title('pred: {} \n actual: {}'.format(classes[preds[idx]], classes[labels[idx]]))

"""# Stroke Data Experiment"""

def get_stroke_data(group, label, start, stop):
  qd2 = QuickDrawDataGroup(group, print_messages=False)
  data = []
  labels = []

  for drawing in itertools.islice(qd2.drawings, start, stop):
      back = Image.new("RGB", (255, 255))
      for stroke in itertools.islice(drawing.strokes, 1, drawing.no_of_strokes):
        img = ImageDraw.Draw(back)
        img.line(stroke, width=2)
        temp = back.copy()
        temp = transforms.ToTensor()(temp)
        data.append(temp)
        labels.append(label)

  return data, labels

class StrokeDataset(Dataset):
  def __init__(self, cat1, cat2, cat3, cat4, cat5, cat6, cat7, cat8, cat9, cat10, start=0, stop=100):
    data1, labels1 = get_stroke_data(cat1, 0, start, stop)
    data2, labels2 = get_stroke_data(cat2, 1, start, stop)
    data3, labels3 = get_stroke_data(cat3, 2, start, stop)
    data4, labels4 = get_stroke_data(cat4, 3, start, stop)
    data5, labels5 = get_stroke_data(cat5, 4, start, stop)
    data6, labels6 = get_stroke_data(cat6, 5, start, stop)
    data7, labels7 = get_stroke_data(cat7, 6, start, stop)
    data8, labels8 = get_stroke_data(cat8, 7, start, stop)
    data9, labels9 = get_stroke_data(cat9, 8, start, stop)
    data10, labels10 = get_stroke_data(cat10, 9, start, stop)
    self.data = data1 + data2 + data3 + data4 + data5 + data6 + data7 + data8 + data9 + data10
    self.labels = labels1 + labels2 + labels3 + labels4 + labels5 + labels6 + labels7 + labels8 + labels9 + labels10
 
  def __len__(self):
      return len(self.data)
 
  def __getitem__(self, idx):
      return self.data[idx], self.labels[idx]

stroke_train_dataset = StrokeDataset('apple', 'basketball', 'cookie', 'dolphin', 'envelope', 'fish', 'golf club', 'headphones', 'ice cream', 'light bulb')
stroke_val_dataset = StrokeDataset('apple', 'basketball', 'cookie', 'dolphin', 'envelope', 'fish', 'golf club', 'headphones', 'ice cream', 'light bulb', 100, 120)
print(len(stroke_train_dataset))
print(len(stroke_val_dataset))
stroke_train_loader = torch.utils.data.DataLoader(stroke_train_dataset, batch_size=64, shuffle=True)
stroke_val_loader = torch.utils.data.DataLoader(stroke_val_dataset, batch_size=20)
#get_accuracy(trained_model, stroke_loader)
model = CNNModel()
train_CNN(model, stroke_train_loader, stroke_val_loader, num_epochs=2)

for i, (inputs, labels) in enumerate(stroke_val_loader):
    classes = ['Apple', 'Basketball', 'Cookie', 'Dolphin', 'Envelope', 'Fish', 'Golf Club', 'Headphones', 'Ice Cream', 'Light Bulb']  
    features = alexnet.features(inputs)
    outputs = trained_model(features)
    _, preds = torch.max(outputs, 1)

    fig = plt.figure(figsize=(25, 4))
    for idx in range(5):
        ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])
        plt.imshow(transforms.ToPILImage()(inputs[idx]))
        ax.set_title('pred: {} \n actual: {}'.format(classes[preds[idx]], classes[labels[idx]]))

"""# RNN Experiment"""

def get_max_strokes(categories, start, stop):
  strokes = []
  coords = []
  for cat in categories:
    qd = QuickDrawDataGroup(cat, print_messages=False)
    for drawing in itertools.islice(qd.drawings, start, stop):
      strokes.append(drawing.no_of_strokes)
      for stroke in drawing.strokes:
        coords.append(len(stroke))
  return max(strokes), max(coords)

def get_RNN_stroke_data(group, label, max_strokes, max_len, start=0, stop=100):
  qd = QuickDrawDataGroup(group, print_messages=False)
  data = []
  labels = []
  stroke_lengths = []
  max_strokes = max_strokes
  max_len = max_len

  for drawing in itertools.islice(qd.drawings, start, stop):
      strokes = drawing.strokes
      stroke_pad = max_strokes - len(strokes)
      for i in range(stroke_pad):
        strokes.append([(0, 0)] * max_len) 
      for stroke in strokes:
        coord_pad = max_len - len(stroke)
        for j in range(coord_pad):
          stroke.append((0, 0))
      strokes = torch.Tensor(strokes)
      #print(strokes.size())
      data.append(strokes)
      labels.append(label)
  
  return data, labels

class StrokeRNNDataset(Dataset):
  def __init__(self, cat1, cat2, cat3, cat4, cat5, cat6, cat7, cat8, cat9, cat10, start=0, stop=100):
    max_strokes, max_len = get_max_strokes([cat1, cat2, cat3, cat4, cat5, cat6, cat7, cat8, cat9, cat10], start, stop)
    data1, labels1 = get_RNN_stroke_data(cat1, 0, max_strokes, max_len, start, stop)
    data2, labels2 = get_RNN_stroke_data(cat2, 1, max_strokes, max_len, start, stop)
    data3, labels3 = get_RNN_stroke_data(cat3, 2, max_strokes, max_len, start, stop)
    data4, labels4 = get_RNN_stroke_data(cat4, 3, max_strokes, max_len, start, stop)
    data5, labels5 = get_RNN_stroke_data(cat5, 4, max_strokes, max_len, start, stop)
    data6, labels6 = get_RNN_stroke_data(cat6, 5, max_strokes, max_len, start, stop)
    data7, labels7 = get_RNN_stroke_data(cat7, 6, max_strokes, max_len, start, stop)
    data8, labels8 = get_RNN_stroke_data(cat8, 7, max_strokes, max_len, start, stop)
    data9, labels9 = get_RNN_stroke_data(cat9, 8, max_strokes, max_len, start, stop)
    data10, labels10 = get_RNN_stroke_data(cat10, 9, max_strokes, max_len, start, stop)
    self.data = data1 + data2 + data3 + data4 + data5 + data6 + data7 + data8 + data9 + data10
    self.labels = labels1 + labels2 + labels3 + labels4 + labels5 + labels6 + labels7 + labels8 + labels9 + labels10
 
  def __len__(self):
      return len(self.data)
 
  def __getitem__(self, idx):
      return self.data[idx], self.labels[idx]

class RNNModel(nn.Module):
  def __init__(self, input_size, hidden_size, num_classes):
      super(RNNModel, self).__init__()
      self.hidden_size = hidden_size
      self.num_classes = num_classes
      self.rnn = nn.LSTM(input_size, hidden_size, num_classes, batch_first=True)
      self.fc = nn.Linear(hidden_size, num_classes)
  
  def forward(self, x):
      # Set an initial hidden state
      h0 = torch.zeros(self.num_classes, x.size(0), self.hidden_size)
      c0 = torch.zeros(self.num_classes, x.size(0), self.hidden_size)
      # Forward propagate the RNN
      out, _ = self.rnn(x, (h0, c0))
      # Pass the output of the last time step to the classifier
      out = self.fc(out[:, -1, :])
      return out

stroke_RNN_train_dataset = StrokeDataset('apple', 'basketball', 'cookie', 'dolphin', 'envelope', 'fish', 'golf club', 'headphones', 'ice cream', 'light bulb')
stroke_RNN_val_dataset = StrokeDataset('apple', 'basketball', 'cookie', 'dolphin', 'envelope', 'fish', 'golf club', 'headphones', 'ice cream', 'light bulb', 100, 120)
stroke_RNN_train_loader = torch.utils.data.DataLoader(stroke_train_dataset, batch_size=64, shuffle=True)
stroke_RNN_val_loader = torch.utils.data.DataLoader(stroke_val_dataset, batch_size=64, shuffle=True)

model = RNNModel(255, hidden_size=30, num_classes=10)

use_cuda = True
if use_cuda and torch.cuda.is_available():
  model.cuda()
  print('CUDA is available!  Training on GPU ...')

train_CNN(model, train_loader, val_loader, num_epochs=5, CNN=False)